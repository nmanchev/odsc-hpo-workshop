{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aa37760d-aa74-4971-81ac-a44cdf479e41",
   "metadata": {},
   "source": [
    "# Getting started with Ray\n",
    "\n",
    "[Ray.io](https://www.ray.io/) is a distributed execution framework that makes it easy to scale your single machine applications, with little or no changes, and to leverage state-of-the-art machine learning libraries.\n",
    "\n",
    "Ray provides a set of core low-level primitives as well as a family of pre-packaged libraries that take advantage of these primitives to enable solving powerful machine learning problems.\n",
    "\n",
    "The following libraries come packaged with Ray:\n",
    "\n",
    "* [Tune](https://docs.ray.io/en/master/tune/index.html): Scalable Hyperparameter Tuning\n",
    "\n",
    "* [RaySGD](https://docs.ray.io/en/releases-1.11.0/raysgd/raysgd.html): Distributed Training Wrappers\n",
    "\n",
    "* [RLlib](https://docs.ray.io/en/latest/rllib/index.html): Industry-Grade Reinforcement Learning\n",
    "\n",
    "* [Ray](https://docs.ray.io/en/master/serve/index.html#rayserve) Serve: Scalable and Programmable Serving\n",
    "\n",
    "Additionally, Ray has been adopted as a foundational framework by a large number of open source ML frameworks which now have community maintained Ray integrations. \n",
    "\n",
    "Domino can dynamically provision and orchestrate a Ray cluster directly on the infrastructure backing the Domino instance. This allows Domino users to get quick access to Ray without having to rely on their IT team. When you start a Domino workspace for interactive work or a Domino job for batch processing, Domino will create, manage for you, and make available to your execution a containerized Ray cluster.\n",
    "\n",
    "Let's start by importing all the libraries needed for this notebook. Note that Ray is already included in our Compute Environment, so no additional installation is needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b17abda3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ray\n",
    "import ray.util\n",
    "import os\n",
    "import time\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3b3f186-f0a1-445c-8ce3-b56a12d40778",
   "metadata": {},
   "source": [
    "When provisioning your on-demand Ray cluster, Domino sets up environment variables that hold the information needed to connect to your cluster. *RAY_HEAD_SERVICE_HOST* and *RAY_HEAD_SERVICE_PORT* hold the hostname and port of the Ray head node. We can pass this to *ray.init()* to establish a connection with the cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c48d6704",
   "metadata": {},
   "outputs": [],
   "source": [
    "if ray.is_initialized() == False:\n",
    "   service_host = os.environ[\"RAY_HEAD_SERVICE_HOST\"]\n",
    "   service_port = os.environ[\"RAY_HEAD_SERVICE_PORT\"]\n",
    "   ray.init(f\"ray://{service_host}:{service_port}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc3826a3-e8d2-4c3d-931f-e94935209da6",
   "metadata": {},
   "source": [
    "Let's confirm that we are now connected to Ray."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7797a6f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ray.is_initialized()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d461a90-c3e6-4e71-8b91-105152621298",
   "metadata": {},
   "source": [
    "Now let's check the health of the nodes, look at their CPU and GPU per node. Here you can see each node, including the head node. It's always a good idea to check this and plan your memory usuage with Ray."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1723f43a-905d-44bc-8891-484534cf8ce0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'NodeID': '86ebdbdb38a064dd4409abaf5792806fed6bcf6d2a2bc7362287909e',\n",
       "  'Alive': True,\n",
       "  'NodeManagerAddress': '10.0.36.183',\n",
       "  'NodeManagerHostname': 'ray-645a8c06935490051989b8bc-ray-worker-0',\n",
       "  'NodeManagerPort': 2385,\n",
       "  'ObjectManagerPort': 2384,\n",
       "  'ObjectStoreSocketName': '/tmp/ray/session_2023-05-09_11-10-07_435787_1/sockets/plasma_store',\n",
       "  'RayletSocketName': '/tmp/ray/session_2023-05-09_11-10-07_435787_1/sockets/raylet',\n",
       "  'MetricsExportPort': 41329,\n",
       "  'alive': True,\n",
       "  'Resources': {'memory': 2957327565.0,\n",
       "   'CPU': 1.0,\n",
       "   'node:10.0.36.183': 1.0,\n",
       "   'object_store_memory': 1267426099.0}},\n",
       " {'NodeID': 'e2be0b1ca427d42cb82601c67ec47b0b0e89b91f5caf97ae65f2c0f0',\n",
       "  'Alive': True,\n",
       "  'NodeManagerAddress': '10.0.95.160',\n",
       "  'NodeManagerHostname': 'ray-645a8c06935490051989b8bc-ray-head-0',\n",
       "  'NodeManagerPort': 2385,\n",
       "  'ObjectManagerPort': 2384,\n",
       "  'ObjectStoreSocketName': '/tmp/ray/session_2023-05-09_11-10-07_435787_1/sockets/plasma_store',\n",
       "  'RayletSocketName': '/tmp/ray/session_2023-05-09_11-10-07_435787_1/sockets/raylet',\n",
       "  'MetricsExportPort': 39189,\n",
       "  'alive': True,\n",
       "  'Resources': {'CPU': 1.0,\n",
       "   'memory': 2414960640.0,\n",
       "   'object_store_memory': 1207480320.0,\n",
       "   'node:10.0.95.160': 1.0}}]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ray.nodes()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3838bb0a-a04b-4198-8cce-a18f9dfd8475",
   "metadata": {},
   "source": [
    "Domino also provides access to a dashboard (Web UI), which allows us to look at the cluster resources like CPU, Disk, and memory consumption.\n",
    "\n",
    "Click on the \"Ray Web UI\" tab in the top right corner to access the Ray dashboard where you can see the cluster nodes, workloads, and available resources.\n",
    "\n",
    "![Ray dashboard](images/ray_dashboard.png \"Ray dashboard\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31f5a798-2285-4e4e-8a87-eb13be2c6e21",
   "metadata": {},
   "source": [
    "## A simple sort excercise\n",
    "\n",
    "Let's define a simple Python bubble sort function. Here we make the choice of algorithm on purpose as it repeatedly steps through the input list element by element, hence it is quite slow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3257a256-f1f9-4d56-9e64-fd62da29ff63",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bubble_sort(to_sort):\n",
    "    n = len(to_sort)\n",
    "    for i in range(n):\n",
    "        for j in range(n - 1):\n",
    "            if to_sort[j] > to_sort[j+1]:\n",
    "                to_sort[j], to_sort[j+1] = to_sort[j+1], to_sort[j]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f70d896c-ee32-4359-9e8b-45d1c5223132",
   "metadata": {},
   "source": [
    "Now let's run this function on a list of 3,000 randomly selected numbers and repeat the process 20 times. We'll time the execution and use it as a baseline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dfe2a1b7-1f93-4f36-8fce-b35605d7a538",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 21.410213947296143 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "[bubble_sort(random.sample(range(1, 1000000), 3000)) for _ in range(20)]\n",
    "print(\"--- %s seconds ---\" % ((time.time() - start_time)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf429460-5738-43c5-990e-11862f07e130",
   "metadata": {},
   "source": [
    "Let's see if Ray can improve on this run time.\n",
    "\n",
    "## Task 1 - Convert *bubble_sort* into a Ray task\n",
    "\n",
    "Ray enables us to execute standard Python functions asynchronously by turning them into Ray tasks (also called Remote Functions).\n",
    "\n",
    "To do this, you decorate your function with *@ray.remote* to declare that you want to run this function remotely. Write a function called *bubble_sort_remote* that is identical to *bubble_sort* but is set up as a Ray task (i.e. decorated with *@ray.remote*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "617b1316-607b-45c6-a718-b7bf491ca6f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "@ray.remote\n",
    "def bubble_sort_remote(to_sort):\n",
    "    n = len(to_sort)\n",
    "    for i in range(n):\n",
    "        for j in range(n - 1):\n",
    "            if to_sort[j] > to_sort[j+1]:\n",
    "                to_sort[j], to_sort[j+1] = to_sort[j+1], to_sort[j]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86e5d4d8-e193-4208-8c7a-c2c947b28745",
   "metadata": {},
   "source": [
    "Now call *bubble_sort_remote*, repeating the 3,000 elements x 20 sort. Remember that calling a Ray task is done via .remote() instead. For example, if you have a standard Python function, which you call as\n",
    "\n",
    "```\n",
    "f1(arg1, arg2)\n",
    "```\n",
    "\n",
    "then its Ray task version should be called as\n",
    "\n",
    "```\n",
    "f1.remote(arg1, arg2)\n",
    "```\n",
    "\n",
    "Don't forget to take a look at the Ray dashboard while *bubble_sort_remote* is executing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c39185f3-5704-4bba-ab40-b73c0b553fe5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 13.810055494308472 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "ray.get([bubble_sort_remote.remote(random.sample(range(1, 1000000), 3000)) for _ in range(20)])\n",
    "print(\"--- %s seconds ---\" % ((time.time() - start_time)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbccd793-ec85-4d64-b97e-4996edae2edf",
   "metadata": {},
   "source": [
    "Note that the *remote()* call above creates an object reference (obj_ref) and a Ray task that is executed on a worker process. \n",
    "The **result** of the execution is then retrieved by calling *ray.get(obj_ref)*. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0f43cdb-9d3f-464b-b7c1-6a14daf49661",
   "metadata": {},
   "source": [
    "# Task dependencies\n",
    "\n",
    "Despite being asynchronous in nature, Ray tasks can still be dependent on other tasks. We could, for example, modify the call to *bubble_sort_remote* in the following way:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "398e4d15-27ab-4510-a1bd-deadda38c210",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 13.937318563461304 seconds ---\n"
     ]
    }
   ],
   "source": [
    "@ray.remote\n",
    "def random_list(n=3000):\n",
    "    return random.sample(range(1, 1000000), n)\n",
    "                    \n",
    "start_time = time.time()\n",
    "ray.get([bubble_sort_remote.remote(random_list.remote()) for _ in range(20)])\n",
    "print(\"--- %s seconds ---\" % ((time.time() - start_time)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd3af768-539f-4dc1-a5ee-e7f97c7e1915",
   "metadata": {},
   "source": [
    "In this case, the random list creation is refactored into a separate Ray task, which is nested within the bubble_sort_remote call. Ray handles these situations transparently by building an internal dependency graph, so there is nothing special that we need to take care of. Just be mindful that in situations like this the actual sorting won't be executed before the random_list task has finished executing. This is generally the case for tasks that depend on each other.\n",
    "\n",
    "In addition, the observant participant may ask, \"Wait, I thought calling a Ray task returns an object reference, not the actual object. Don't I need to call *ray.get()* and pass that to *bubble_sort_remote.remote()*?\" The answer is no; Ray does this step for us."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "170b2f6e-046e-4bdb-bf1d-7d0bf3263942",
   "metadata": {},
   "source": [
    "# Actors\n",
    "\n",
    "So far we have looked at how to transform simple Python functions into Ray tasks. Actors further extend the API to Python classes. Similar to the transformation of functions, decorating a Python class with @ray.remote transforms it into a stateful actor. Every instance of a class decorated with *@ray.remote* results in a new process (actor) that Ray starts somewhere on the cluster. Every call to an instance method is executed as a Ray task, which can mutate the state of the actor. \n",
    "\n",
    "Let's look at an example. Here is a simple class that implements our sinking sort algorithm:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "76879ba2-d65c-4d93-8164-613368c9e015",
   "metadata": {},
   "outputs": [],
   "source": [
    "@ray.remote\n",
    "class Bubble_Remote(object):\n",
    "\n",
    "    def __init__(self):\n",
    "      self.to_sort = self.shuffle()\n",
    "    \n",
    "    def shuffle(self):\n",
    "        return random.sample(range(1, 1000000), 3000)\n",
    "    \n",
    "    def sort(self):\n",
    "        n = len(self.to_sort)\n",
    "        for i in range(n):\n",
    "            for j in range(n - 1):\n",
    "                if self.to_sort[j] > self.to_sort[j+1]:\n",
    "                    self.to_sort[j], self.to_sort[j+1] = self.to_sort[j+1], self.to_sort[j]\n",
    "                    \n",
    "    def get_value(self):\n",
    "        return self.to_sort"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "858fd054-7dc3-4f74-9838-6e7853e44891",
   "metadata": {},
   "source": [
    "As you can see above, besides the decorator, there is nothing special about the class. The class encapsulates our *bubble_sort* method, a *shuffle* method that randomly initialises the *to_sort* class member, and one getter method for retrieving the sorted list. The latter is needed because we can't read fields in Ray actors directly. \n",
    "\n",
    "Using the code above is pretty straightforward, but pay attention to how the class is being instantiated:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2c3f63cf-cd37-4b41-a81b-5ecd268257ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsorted: [723075, 941639, 754831, 791515, 191244, 290100, 489127, 769594, 604909, 970304]\n",
      "Sorted: [368, 418, 440, 886, 919, 1068, 1355, 1388, 1399, 1589]\n",
      "--- 1.852614164352417 seconds ---\n"
     ]
    }
   ],
   "source": [
    "bubble_remote = Bubble_Remote.remote()\n",
    "print(\"Unsorted:\", ray.get(bubble_remote.get_value.remote())[:10])\n",
    "start_time = time.time()\n",
    "bubble_remote.sort.remote()\n",
    "print(\"Sorted:\", ray.get(bubble_remote.get_value.remote())[:10])\n",
    "print(\"--- %s seconds ---\" % ((time.time() - start_time)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ad639c5-5a14-4ec4-8631-003af91e4210",
   "metadata": {},
   "source": [
    "What about parallelisation? Let's do another 20 runs of shuffling and sorting, and check the wall clock."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "47453503-0423-4551-a83d-c96e11799a5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 24.511674404144287 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "for _ in range(20):\n",
    "    bubble_remote.shuffle.remote()\n",
    "    ray.get(bubble_remote.sort.remote())\n",
    "print(\"--- %s seconds ---\" % ((time.time() - start_time)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6976ddf8-369b-48ec-930e-af6f65128de1",
   "metadata": {},
   "source": [
    "OK, it appears that this is as slow as a normal single-threaded Python execution.\n",
    "\n",
    "Let's terminate the *bubble_remote* actor as we'll need the resources it currently uses for what follows. You can optionally check the Logical View of the Ray Web UI tab before and after executing the next cell and see how the Alive value for BubbleRemote changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "09acc226-f2a1-41c3-9d75-a2d986ce1650",
   "metadata": {},
   "outputs": [],
   "source": [
    "ray.kill(bubble_remote)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54479d5e-3363-4575-bd0d-2a12db524b3d",
   "metadata": {},
   "source": [
    "The reason for the slow execution above is because methods called on the same actor are executed serially in the order that they are called. Remember that actors are stateful, so Ray can't allow multiple remote functions to change class members out of order. This behaviour may look disappointing at first, but keep the following in mind:\n",
    "\n",
    "* methods on different actors are executed in parallel\n",
    "* actor handles can be passed to remote functions and other actors, and they can call each other\n",
    "\n",
    "The above properties enable us to design highly complex execution graphs with a substantial degree of parallelism. Here is an example from the official [Ray documentation](https://docs.ray.io/) that illustrates building a tree of actors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ea38b780-09a0-499a-b200-8c93dd239670",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['done', 'done', 'done']\n"
     ]
    }
   ],
   "source": [
    "@ray.remote(num_cpus=.5)\n",
    "class Worker:\n",
    "    def work(self):\n",
    "        return \"done\"\n",
    "\n",
    "@ray.remote(num_cpus=.5)\n",
    "class Supervisor:\n",
    "    def __init__(self):\n",
    "        self.workers = [Worker.remote() for _ in range(3)]\n",
    "    def work(self):\n",
    "        return ray.get([w.work.remote() for w in self.workers])\n",
    "\n",
    "sup = Supervisor.remote()\n",
    "print(ray.get(sup.work.remote()))  # outputs ['done', 'done', 'done']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56ca44f2-7ce5-4c4b-9270-348561ad0b6e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
